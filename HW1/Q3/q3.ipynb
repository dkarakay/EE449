{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Files already downloaded and verified\n",
      "Sample image size:  torch.Size([1, 32, 32])\n",
      "Training data size: 45000\n",
      "Validation data size: 5000\n",
      "Test data size: 10000\n",
      "Training mlp1...\n",
      "Epoch [1/15], Epoch Time: 1.8962 s, Validation Accuracy: 0.3334\n",
      "Epoch [2/15], Epoch Time: 1.7566 s, Validation Accuracy: 0.3620\n",
      "Epoch [3/15], Epoch Time: 1.7280 s, Validation Accuracy: 0.3644\n",
      "Epoch [4/15], Epoch Time: 1.7585 s, Validation Accuracy: 0.3824\n",
      "Epoch [5/15], Epoch Time: 1.7627 s, Validation Accuracy: 0.3854\n",
      "Epoch [6/15], Epoch Time: 1.7711 s, Validation Accuracy: 0.3798\n",
      "Epoch [7/15], Epoch Time: 2.1196 s, Validation Accuracy: 0.3796\n",
      "Epoch [8/15], Epoch Time: 1.7888 s, Validation Accuracy: 0.3814\n",
      "Epoch [9/15], Epoch Time: 1.7191 s, Validation Accuracy: 0.3858\n",
      "Epoch [10/15], Epoch Time: 1.7375 s, Validation Accuracy: 0.3852\n",
      "Epoch [11/15], Epoch Time: 1.8217 s, Validation Accuracy: 0.3860\n",
      "Epoch [12/15], Epoch Time: 1.7367 s, Validation Accuracy: 0.3860\n",
      "Epoch [13/15], Epoch Time: 1.8114 s, Validation Accuracy: 0.3892\n",
      "Epoch [14/15], Epoch Time: 1.7851 s, Validation Accuracy: 0.3828\n",
      "Epoch [15/15], Epoch Time: 1.7788 s, Validation Accuracy: 0.3860\n",
      "AFTER 1 training: 0.3926\n",
      "Process: 32.3413 s\n",
      "Epoch [1/15], Epoch Time: 1.7341 s, Validation Accuracy: 0.3874\n",
      "Epoch [2/15], Epoch Time: 1.7426 s, Validation Accuracy: 0.3810\n",
      "Epoch [3/15], Epoch Time: 1.6972 s, Validation Accuracy: 0.3888\n",
      "Epoch [4/15], Epoch Time: 1.6871 s, Validation Accuracy: 0.3758\n",
      "Epoch [5/15], Epoch Time: 1.6982 s, Validation Accuracy: 0.3820\n",
      "Epoch [6/15], Epoch Time: 1.7259 s, Validation Accuracy: 0.3898\n",
      "Epoch [7/15], Epoch Time: 1.7072 s, Validation Accuracy: 0.3826\n",
      "Epoch [8/15], Epoch Time: 1.7145 s, Validation Accuracy: 0.3818\n",
      "Epoch [9/15], Epoch Time: 1.7257 s, Validation Accuracy: 0.3770\n",
      "Epoch [10/15], Epoch Time: 1.7033 s, Validation Accuracy: 0.3806\n",
      "Epoch [11/15], Epoch Time: 1.7050 s, Validation Accuracy: 0.3788\n",
      "Epoch [12/15], Epoch Time: 1.7309 s, Validation Accuracy: 0.3740\n",
      "Epoch [13/15], Epoch Time: 1.7095 s, Validation Accuracy: 0.3718\n",
      "Epoch [14/15], Epoch Time: 1.7214 s, Validation Accuracy: 0.3890\n",
      "Epoch [15/15], Epoch Time: 1.6980 s, Validation Accuracy: 0.3700\n",
      "AFTER 2 training: 0.3926\n",
      "Process: 58.7044 s\n",
      "Best performance formlp1: 0.3926\n",
      "Process: 58.7044 s\n"
     ]
    }
   ],
   "source": [
    "# Created by Deniz Karakay at 17.04.2023\n",
    "# Filename: question_3.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from Q3 import models as my_models\n",
    "\n",
    "# Hyper-parameters\n",
    "EPOCH_SIZE = 15\n",
    "BATCH_SIZE = 50\n",
    "TRAIN_COUNT = 2\n",
    "\n",
    "# I tested and saw that CPU is faster than GPU on M1 Pro\n",
    "\n",
    "# MPS for GPU support on M1\n",
    "# device = torch.device(\"mps\")\n",
    "\n",
    "# CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "init_time = time.time()\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    torchvision.transforms.Grayscale()\n",
    "])\n",
    "\n",
    "# Load data\n",
    "train_data = torchvision.datasets.CIFAR10('data/', train=True, download=True, transform=transform)\n",
    "\n",
    "# Print image size and label of first image in dataset (should be 32x32 and 6)\n",
    "img, label = train_data[0]\n",
    "print(\"Sample image size: \", img.size())\n",
    "\n",
    "# Split data into training and validation\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Load test data\n",
    "test_data = torchvision.datasets.CIFAR10('data/', train=False, transform=transform)\n",
    "\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Validation data size: {len(valid_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "valid_generator = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "my_models = {'mlp1': my_models.MLP1(1024, 32, 10).to(device)}\n",
    "# 'mlp2': my_models.MLP2(1024, 32, 64, 10).to(device),\n",
    "# }\n",
    "\n",
    "for model_name, model in my_models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    best_performance = 0\n",
    "    best_weights = None\n",
    "\n",
    "    train_acc_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    valid_acc_history_total = []\n",
    "    test_acc_history_total = []\n",
    "\n",
    "    for tc in range(TRAIN_COUNT):\n",
    "        train_acc_history = []\n",
    "        train_loss_history = []\n",
    "        valid_acc_history = []\n",
    "        test_acc_history = []\n",
    "        for epoch in range(EPOCH_SIZE):\n",
    "            start_time = time.time()  # start timer\n",
    "            train_generator = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "            total_step = len(train_generator)\n",
    "            for i, data in enumerate(train_generator):\n",
    "                model.train()\n",
    "                inputs, labels = data\n",
    "                train_inputs, train_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward + backward + optimize\n",
    "                train_outputs = model(train_inputs)\n",
    "                loss = criterion(train_outputs, train_labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_correct = 0\n",
    "                if i % 10 == 9:\n",
    "                    model.eval()\n",
    "                    # Compute training accuracy\n",
    "                    _, train_predicted = torch.max(train_outputs, 1)\n",
    "                    train_total = train_labels.size(0)\n",
    "                    train_correct += (train_predicted == train_labels).sum().item()\n",
    "\n",
    "                    train_acc = train_correct / train_total\n",
    "\n",
    "                    # Save training loss\n",
    "                    train_loss = loss.item()\n",
    "\n",
    "                    valid_correct = 0\n",
    "                    valid_total = 0\n",
    "                    with torch.no_grad():\n",
    "                        for data in valid_generator:\n",
    "                            inputs, labels = data\n",
    "                            valid_inputs, valid_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                            # Compute the outputs and predictions\n",
    "                            valid_outputs = model(valid_inputs)\n",
    "                            _, valid_predicted = torch.max(valid_outputs.data, 1)\n",
    "\n",
    "                            # Track the statistics\n",
    "                            valid_total += valid_labels.size(0)\n",
    "                            valid_correct += (valid_predicted == valid_labels).sum().item()\n",
    "\n",
    "                    valid_acc = valid_correct / valid_total\n",
    "\n",
    "                    valid_acc_history.append(valid_acc)\n",
    "                    train_acc_history.append(train_acc)\n",
    "                    train_loss_history.append(train_loss)\n",
    "                    # print(f'Train accuracy: {train_acc:.3f}')\n",
    "\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{EPOCH_SIZE}], Epoch Time: {epoch_time:.4f} s, Validation Accuracy: {valid_acc:.4f}\")\n",
    "\n",
    "        train_acc_history_total.append(train_acc_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        valid_acc_history_total.append(valid_acc_history)\n",
    "\n",
    "        # Evaluate the model on test set\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            test_generator = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            model.eval()\n",
    "            for data in test_generator:\n",
    "                inputs, labels = data\n",
    "                test_inputs, test_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Compute the outputs and predictions\n",
    "                test_outputs = model(test_inputs)\n",
    "                _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "\n",
    "                # Track the statistics\n",
    "                test_total += test_labels.size(0)\n",
    "                test_correct += (test_predicted == test_labels).sum().item()\n",
    "                test_acc = test_correct / test_total\n",
    "\n",
    "            # Save best weights\n",
    "            if test_acc > best_performance:\n",
    "                best_performance = test_acc\n",
    "                best_weights = model.fc1.weight.data.cpu().numpy()\n",
    "\n",
    "            # Save test accuracy\n",
    "            test_acc_history.append(test_acc)\n",
    "\n",
    "        took_time = time.time() - init_time\n",
    "        print(f\"Training [{tc + 1}/{TRAIN_COUNT}], {took_time:.4f} s, Test Accuracy: {best_performance:.4f}\")\n",
    "\n",
    "        test_acc_history_total.append(test_acc_history)\n",
    "\n",
    "    took_time = time.time() - init_time\n",
    "    print(f\"Best performance for {model_name}: {best_performance:.4f}, took {took_time:.4f} s\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test accuracy: 0.3926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Average training loss\n",
    "t = np.array(train_loss_history_total)\n",
    "average_train_loss = np.mean(t, axis=0)\n",
    "\n",
    "# Average training accuracy\n",
    "t = np.array(train_acc_history_total)\n",
    "average_train_acc = np.mean(t, axis=0)\n",
    "\n",
    "# Average validation accuracy\n",
    "t = np.array(valid_acc_history_total)\n",
    "average_valid_acc = np.mean(t, axis=0)\n",
    "\n",
    "best_test_acc = np.max(test_acc_history_total)\n",
    "print(f\"Best test accuracy: {best_test_acc:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All process: 574.2896 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_dict = {\n",
    "    'name': model_name,\n",
    "    'loss_curve': average_train_loss,\n",
    "    'train_acc_curve': average_train_acc,\n",
    "    'val_acc_curve': average_valid_acc,\n",
    "    'test_acc': best_test_acc,\n",
    "    'weights': best_weights\n",
    "}\n",
    "\n",
    "import pickle\n",
    "\n",
    "# save the dictionary object to a file\n",
    "filename = 'question_3_' + model_name.replace(' ', '_') + '.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(result_dict, f)\n",
    "\n",
    "took_time = time.time() - init_time\n",
    "print(f\"All process: {took_time:.4f} s\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
