{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding='valid')\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=5, stride=1, padding='valid')\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=7, stride=1, padding='valid')\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.pred_layer = nn.Linear(in_features=144, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.pred_layer(x)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Files already downloaded and verified\n",
      "Sample image size:  torch.Size([1, 32, 32])\n",
      "Training data size: 45000\n",
      "Validation data size: 5000\n",
      "Test data size: 10000\n",
      "Training cnn3...\n",
      "Epoch [1/15], Epoch Time: 80.9689 s, Validation Accuracy: 0.4388\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 109\u001B[0m\n\u001B[1;32m    106\u001B[0m train_outputs \u001B[38;5;241m=\u001B[39m model(train_inputs)\n\u001B[1;32m    107\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(train_outputs, train_labels)\n\u001B[0;32m--> 109\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m9\u001B[39m:\n",
      "File \u001B[0;32m~/.virtualenvs/449/lib/python3.11/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/449/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Created by Deniz Karakay at 17.04.2023\n",
    "# Filename: question_3.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "from Q3 import models as my_models\n",
    "from utils.utils import visualizeWeights\n",
    "\n",
    "# Hyper-parameters\n",
    "EPOCH_SIZE = 15\n",
    "BATCH_SIZE = 50\n",
    "TRAIN_COUNT = 2\n",
    "\n",
    "# I tested and saw that CPU is faster than GPU on M1 Pro\n",
    "\n",
    "# MPS for GPU support on M1\n",
    "# device = torch.device(\"mps\")\n",
    "\n",
    "# CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "init_time = time.time()\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    torchvision.transforms.Grayscale()\n",
    "])\n",
    "\n",
    "# Load data\n",
    "train_data = torchvision.datasets.CIFAR10('data/', train=True, download=True, transform=transform)\n",
    "\n",
    "# Print image size and label of first image in dataset (should be 32x32 and 6)\n",
    "img, label = train_data[0]\n",
    "print(\"Sample image size: \", img.size())\n",
    "\n",
    "# Split data into training and validation\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Load test data\n",
    "test_data = torchvision.datasets.CIFAR10('data/', train=False, transform=transform)\n",
    "\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Validation data size: {len(valid_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")\n",
    "\n",
    "valid_generator = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "my_models = {\n",
    "    'mlp1': my_models.MLP1(1024, 32, 10).to(device),\n",
    "    'mlp2': my_models.MLP2(1024, 32, 64, 10).to(device),\n",
    "    'cnn3': CNN3().to(device),\n",
    "}\n",
    "\n",
    "for model_name, model in my_models.items():\n",
    "    if model_name == 'mlp1' or model_name == 'mlp2':\n",
    "        continue\n",
    "\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    model_init_time = time.time()\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    best_performance = 0\n",
    "    best_weights = None\n",
    "\n",
    "    train_acc_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    valid_acc_history_total = []\n",
    "    test_acc_history_total = []\n",
    "\n",
    "    for tc in range(TRAIN_COUNT):\n",
    "\n",
    "        # Initialize lists for training and validation accuracy and loss\n",
    "        train_acc_history = []\n",
    "        train_loss_history = []\n",
    "        valid_acc_history = []\n",
    "        test_acc_history = []\n",
    "\n",
    "        for epoch in range(EPOCH_SIZE):\n",
    "            # Train the model\n",
    "            start_time = time.time()\n",
    "            train_generator = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "            total_step = len(train_generator)\n",
    "\n",
    "            for i, data in enumerate(train_generator):\n",
    "                model.train()\n",
    "                inputs, labels = data\n",
    "                train_inputs, train_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward + backward + optimize\n",
    "                train_outputs = model(train_inputs)\n",
    "                loss = criterion(train_outputs, train_labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if i % 10 == 9:\n",
    "                    model.eval()\n",
    "                    # Compute training accuracy\n",
    "                    _, train_pred = torch.max(train_outputs, 1)\n",
    "                    train_size = train_labels.size(0)\n",
    "                    train_corrects = torch.sum(train_pred == train_labels.data)\n",
    "\n",
    "                    train_acc = train_corrects / train_size\n",
    "\n",
    "                    # Save training loss\n",
    "                    train_loss = loss.item()\n",
    "\n",
    "                    valid_correct = 0\n",
    "                    valid_total = 0\n",
    "                    with torch.no_grad():\n",
    "                        for data in valid_generator:\n",
    "                            inputs, labels = data\n",
    "                            valid_inputs, valid_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                            # Compute the outputs and predictions\n",
    "                            valid_outputs = model(valid_inputs)\n",
    "                            _, valid_predicted = torch.max(valid_outputs.data, 1)\n",
    "\n",
    "                            # Track the statistics\n",
    "                            valid_total += valid_labels.size(0)\n",
    "                            valid_correct += (valid_predicted == valid_labels).sum().item()\n",
    "\n",
    "                    valid_acc = valid_correct / valid_total\n",
    "\n",
    "                    valid_acc_history.append(valid_acc)\n",
    "                    train_acc_history.append(train_acc)\n",
    "                    train_loss_history.append(train_loss)\n",
    "                    # print(f'Train accuracy: {train_acc:.3f}')\n",
    "\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{EPOCH_SIZE}], Epoch Time: {epoch_time:.4f} s, Validation Accuracy: {valid_acc:.4f}\")\n",
    "\n",
    "        train_acc_history_total.append(train_acc_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        valid_acc_history_total.append(valid_acc_history)\n",
    "\n",
    "        # Evaluate the model on test set\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            test_generator = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            model.eval()\n",
    "            for data in test_generator:\n",
    "                inputs, labels = data\n",
    "                test_inputs, test_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Compute the outputs and predictions\n",
    "                test_outputs = model(test_inputs)\n",
    "                _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "\n",
    "                # Track the statistics\n",
    "                test_total += test_labels.size(0)\n",
    "                test_correct += (test_predicted == test_labels).sum().item()\n",
    "                test_acc = test_correct / test_total\n",
    "\n",
    "            # Save best weights\n",
    "            if test_acc > best_performance:\n",
    "                best_performance = test_acc\n",
    "                best_weights = model.fc1.weight.data.cpu().numpy()\n",
    "\n",
    "            # Save test accuracy\n",
    "            test_acc_history.append(test_acc)\n",
    "\n",
    "        took_time = time.time() - model_init_time\n",
    "        print(f\"Training [{tc + 1}/{TRAIN_COUNT}], {took_time:.4f} s, Test Accuracy: {best_performance:.4f}\")\n",
    "\n",
    "        test_acc_history_total.append(test_acc_history)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "took_time = time.time() - model_init_time\n",
    "print(f\"Best performance for {model_name}: {best_performance:.4f}, took {took_time:.4f} s\")\n",
    "\n",
    "# Average training loss\n",
    "t = np.array(train_loss_history_total)\n",
    "average_train_loss = np.mean(t, axis=0)\n",
    "\n",
    "# Average training accuracy\n",
    "t = np.array(train_acc_history_total)\n",
    "average_train_acc = np.mean(t, axis=0)\n",
    "\n",
    "# Average validation accuracy\n",
    "t = np.array(valid_acc_history_total)\n",
    "average_valid_acc = np.mean(t, axis=0)\n",
    "\n",
    "best_test_acc = np.max(test_acc_history_total)\n",
    "print(f\"Best test accuracy: {best_test_acc:.4f}\")\n",
    "\n",
    "# Save the results\n",
    "result_dict = {\n",
    "    'name': model_name,\n",
    "    'loss_curve': average_train_loss,\n",
    "    'train_acc_curve': average_train_acc,\n",
    "    'val_acc_curve': average_valid_acc,\n",
    "    'test_acc': best_test_acc,\n",
    "    'weights': best_weights\n",
    "}\n",
    "\n",
    "# Save the results to a file\n",
    "filename = 'results/question_3_' + model_name.replace(' ', '_') + '.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(result_dict, f)\n",
    "\n",
    "took_time = time.time() - model_init_time\n",
    "print(f\"All process for {model_name}: {took_time:.4f} s\")\n",
    "\n",
    "visualizeWeights(best_weights, save_dir='results/',\n",
    "                 filename='question_3_weights_' + model_name.replace(' ', '_'))\n",
    "\n",
    "took_time = time.time() - init_time\n",
    "print(f\"All process: {took_time:.4f} s\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
